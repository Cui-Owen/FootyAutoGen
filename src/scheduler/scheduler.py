from apscheduler.schedulers.blocking import BlockingScheduler
from datetime import datetime
from src.crawler.football_italia import fetch_latest_articles
from src.processor.translator import Translator
from src.storage.database import get_db_session
from src.storage.models import Article
import logging

logging.basicConfig(
    filename="logs/scheduler.log",
    format="%(asctime)s %(levelname)s:%(message)s",
    level=logging.INFO,
)


def fetch_and_store_job():
    logging.info(f"[{datetime.now()}] ğŸŸ¢ å®šæ—¶ä»»åŠ¡å¯åŠ¨")

    translator = Translator()
    articles = fetch_latest_articles(limit=3)

    with next(get_db_session()) as db:
        for article in articles:
            chinese_summary = translator.translate_and_summarize(article["content"])

            existing = db.query(Article).filter_by(url=article["url"]).first()
            if existing:
                logging.info(f"âš ï¸ å·²å­˜åœ¨æ–‡ç« ï¼Œè·³è¿‡: {article['title']}")
                continue

            new_article = Article(
                source="football_italia",
                title=article["title"],
                url=article["url"],
                english_content=article["content"],
                chinese_summary=chinese_summary,
            )
            db.add(new_article)
            logging.info(f"âœ… å·²ä¿å­˜æ–‡ç« åˆ°æ•°æ®åº“: {article['title']}")

        db.commit()
    logging.info(f"[{datetime.now()}] ğŸŸ¢ å®šæ—¶ä»»åŠ¡ç»“æŸ\n")


def run_scheduler():
    scheduler = BlockingScheduler()

    # æ¯20åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
    scheduler.add_job(fetch_and_store_job, "interval", minutes=20)

    logging.info("ğŸŸ¢ è°ƒåº¦å™¨å¯åŠ¨ï¼Œå®šæ—¶ä»»åŠ¡æ¯20åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
    scheduler.start()


if __name__ == "__main__":
    run_scheduler()
